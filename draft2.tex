\documentclass[manuscript,screen,review]{acmart}
\usepackage{placeins}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{multirow} 
% \usepackage[margin=1in]{geometry}
% \usepackage{tcolorbox}
\usepackage[most]{tcolorbox}
\usepackage{caption} % Required for captionof






\setlength{\headheight}{20.48303pt}
\addtolength{\topmargin}{-7.48303pt}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}
\setcopyright{none}
\usepackage{rotating}
\usepackage{array}
% \usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{adjustbox}


\usepackage[bidi=default, english]{babel}
\usepackage[LAE, T1]{fontenc}

\AtBeginDocument{\let\beginL\relax \let\endL\relax}
\usepackage{tcolorbox}


\newtcolorbox{mybox}{
  colback=black!5!white,
  colframe=black,
  arc=5pt,
  boxrule=0.8pt,
  width=\textwidth,
  before skip=10pt, % Add space before the box
  after skip=10pt   % Add space after the box
}

\begin{document}
\title{EgyMed: Generating and Evaluating Arabic Medical Dialogues Using Prompt Engineering and Thought-Based Assessment}

\author{Mariam Nabil}
\affiliation{%
  \institution{Center for Informatics Science (CIS), School of Information Technology and Computer Science, Nile University}
  \city{Sheikh Zayed City}
  \state{Giza}
  \country{Egypt}
}
\email{M.Nabil2184@nu.edu.eg}


\author{Marryam Yahya}
\affiliation{%
  \institution{Center for Informatics Science (CIS), School of Information Technology and Computer Science, Nile University}
  \city{Sheikh Zayed City}
  \state{Giza}
  \country{Egypt}
}
\email{M.Yahya2163@nu.edu.eg}


\author{Yomna Ashraf}
\affiliation{%
  \institution{Center for Informatics Science (CIS), School of Information Technology and Computer Science, Nile University}
  \city{Sheikh Zayed City}
  \state{Giza}
  \country{Egypt}
}
\email{Y.Ashraf2278@nu.edu.eg}

\author{Esraa Ismail}
\affiliation{%
  \institution{Center for Informatics Science (CIS), School of Information Technology and Computer Science, Nile University}
  \city{Sheikh Zayed City}
  \state{Giza}
  \country{Egypt}
}
\email{E.Ismail2165@nu.edu.eg}

\author{Ziad Elshaer}
\affiliation{%
  \institution{Center for Informatics Science (CIS), School of Information Technology and Computer Science, Nile University}
  \city{Sheikh Zayed City}
  \state{Giza}
  \country{Egypt}
}
\email{ZElshaer@nu.edu.eg}


\author{Ghada Khoriba}
\affiliation{%
  \institution{Center for Informatics Science (CIS), School of Information Technology and Computer Science, Nile University}
  \city{Sheikh Zayed City}
  \state{Giza}
  \country{Egypt}
}
\affiliation{\institution{ Faculty of Computers and Artificial Intelligence, Helwan University}
\country{Egypt}}
\email{GhadaKhoriba@nu.edu.eg}

\begin{abstract}

\end{abstract}

\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010147.10010178.10010179</concept_id>
  <concept_desc>Computing methodologies~Natural language processing</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010147.10010178</concept_id>
  <concept_desc>Computing methodologies~Artificial intelligence</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010147.10010257.10010258</concept_id>
  <concept_desc>Computing methodologies~Machine learning approaches</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10010147.10010341</concept_id>
  <concept_desc>Computing methodologies~Modeling and simulation</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Natural language processing}
\ccsdesc[300]{Computing methodologies~Artificial intelligence}
\ccsdesc[100]{Computing methodologies~Machine learning approaches}

\begin{abstract}
Arabic medical dialogue generation is a challenging task in Natural Language Processing, restricted by complex medical terminology, dialectal variations, and the absence of high-quality Arabic medical dialogue datasets. Existing dialogue systems lack data-efficient methods intended for this scope. To address this gap, we introduce EgyMed, a dataset comprising 500 Arabic medical dialogues in both Egyptian Arabic and Modern Standard Arabic (MSA), generated through prompt engineering and thought-based assessment. Our methodology employs the Chain of Thoughts technique for dialogue generation, followed by an extensive evaluation process: RAGEval for hallucination and completeness, LLM-to-LLM evaluation for clarity, completeness, and appropriateness, expert domain evaluation, and a Tree of Thoughts (ToT)-based classification model for medical department prediction, evaluated using BERTScore. We compare our approach against existing dialogue datasets, achieving a BERTScore-F1 of 92.96\% for department prediction, a completeness score of 79.11\%, a hallucination rate of 20.89\% (RAGEval), LLM-to-LLM scores of 6.42/10 (clarity), 4.86/10 (completeness), and 6.89/10 (appropriateness), and an expert evaluation score of 4.8/5. The findings demonstrate the reliability of the EgyMed dataset and the efficacy of our methodology, providing a basis for precise and appropriate Arabic medical dialogue systems in healthcare.
\end{abstract}
\keywords{Arabic Dialogue Generations, LLMs, Prompt Engineering, Chain of Thoughts}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
Arabic medical dialogue generation, a key challenge in computational linguistics, involves creating rational, medically accurate conversations in dialects like Egyptian Arabic and Modern Standard Arabic (MSA) \cite{almutairi-etal-2024-synthetic}. This research enhances healthcare applications by improving patient engagement and optimizing clinical operations for low-resource languages, such as Arabic.

AI-driven dialogue systems require high-quality datasets for training and evaluation. However, Arabic medical dialogue generation faces issues due to linguistic complexity, dialectal variations, and scarce annotated medical dialogue datasets \cite{Abdelhay2023Deep, al2024ahd}. These challenges are compounded by the need for linguistic and medical accuracy, as AI models may produce plausible but incorrect or hallucinated information \cite{daoud2025medarabiqbenchmarkinglargelanguage}. Unlike English, which has robust healthcare dialogue datasets \cite{he2020meddialoglargescalemedicaldialogue, liu2022meddgentitycentricmedicalconsultation}, Arabic lacks comparable resources, hindering high-quality medical dialogue systems.

Existing dialogue generation methods, primarily for English or non-medical contexts \cite{naous2021empatheticbert2bertconversationalmodel, shi2024medicaldialoguesurveycategories}, rely on large annotated datasets, unavailable for Arabic.

To address this, we introduce EgyMed, a dataset of 500 Arabic medical dialogues across various medical departments, generated using Chain of Thought (CoT) prompting with LLMs (GPT-4o \cite{gpt4o2024system}, Silma \cite{silma_01_2024}). We propose a comprehensive evaluation methodology using RAGEval \cite{zhu2024ragevalscenariospecificrag} for hallucination and completeness, LLM-to-LLM evaluation for clarity and appropriateness, expert validation for medical accuracy, and Tree of Thoughts (ToT)-based classification for medical departments, assessed with BERTScore \cite{zhang2020bertscoreevaluatingtextgeneration}.

Our contributions are:
\begin{enumerate}
\item EgyMed, a dataset of 500 Arabic medical dialogues created using CoT prompting with GPT-4o and Silma, ensuring coherent, medically relevant exchanges in Egyptian and MSA dialects.
\item A robust evaluation framework combining RAGEval for hallucination and completeness, LLM-to-LLM evaluation, expert validation, and ToT-based department classification, assessed with BERTScore.
\item Strong empirical results, with a BERTScore-F1 of 92.96\% for department classification, high completeness, and expert scores, validating our dataset and methodology for Arabic medical dialogue systems.
\end{enumerate}

These contributions provide a vital resource and evaluation framework for Arabic medical AI, ensuring trustworthy reasoning, clinical relevance, and dialectal sensitivity. The paper is organized as follows: Section 2 reviews Related Work, Section 3 details Methodology, Section 4 discusses Results, and Section 5 concludes the study.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
Recent advancements in medical dialogue systems (MDS) have enhanced their performance and relevance through high-quality datasets and synthetic dialogue generation techniques. 

Medical dialogue generation has improved by integrating specialized knowledge and enhancing contextual accuracy, as \cite{tang2023terminologyawaremedicaldialoguegeneration, zhao2022medicaldialogueresponsegeneration} suggested.
Additionally, \cite{naseem-etal-2022-incorporating} presented 
a medical knowledge graph (KG), where a knowledge layer queries relevant triples to create a knowledge-rich word tree. Tested on the MedDialog \cite{chen2020meddiag} dataset, this approach exceeded baselines, revealing the importance of detailed medical knowledge for clinically possible replies \cite{naseem-etal-2022-incorporating}. Similarly, \cite{Varshney2023Knowledge} proposed the Masked Entity Dialogue (MED) model, which uses augmented medical knowledge graphs
\cite{Bodenreider2004The} and BERT-based entity prediction. Evaluated on MedDialog(EN) \cite{chen2020meddiag} \& Covid datasets, the MED model performed notable improvements in BLEU \cite{Papineni02bleu:a} and F1-scores \cite{Varshney2023Knowledge}. Also, \cite{xu-etal-2023-medical} developed the Dual Flow enhanced Medical framework, capturing medical entity changes and dialogue acts.

In dialect-specific contexts, \cite{10783570} used the Chain of Thoughts (CoT) technique to improve the logical reasoning in an Egyptian Arabic medical chatbot.

High-quality datasets are critical for training and evaluating MDS. \cite{zeng-etal-2020-meddialog} introduced MedDialog, a large-scale multilingual dataset in English and Chinese.
Similarly, \cite{saley-etal-2024-meditod} introduced MeditOD \cite{saley2024meditodenglishdialoguedataset}, an extensive dataset annotated for medical history-taking dialogues. \cite{saley-etal-2024-meditod}. In the Chinese context, \cite{10.1007/978-3-031-17120-8_35} released MedDG \cite{liu2022meddgentitycentricmedicalconsultation}, a large-scale entity-annotated dataset with almost 18,000 dialogues, including annotations for medical entities \cite{10.1007/978-3-031-17120-8_35}.

In the Arabic domain, \cite{al2024ahd} developed the Arabic Healthcare Dataset (AHD), supporting NLP tasks. \cite{al2024ahd}. Similarly, \cite{Abdelhay2023Deep} introduced MAQA, the largest Arabic Healthcare Q\&A dataset. Synthetic dialogue generation has emerged to address data scarcity and privacy concerns. \cite{das2024syntheticpatientphysiciandialoguegeneration} used clinical notes to generate synthetic patient-physician dialogues\cite{das2024syntheticpatientphysiciandialoguegeneration}. 

While \cite{liu-etal-2022-prophetchat} utilized simulated dialogues to enhance the generated responses. 
Similarly, \cite{almutairi-etal-2024-synthetic} tackled the scarcity of Arabic medical datasets by generating synthetic dialogues in the Saudi Najdi dialect
\cite{almutairi-etal-2024-synthetic}. Also, \cite{wang2023umassbionlpmediqachat2023llms} explored synthetic doctor-patient conversations for clinical documentation, enhancing data diversity and privacy compliance \cite{wang2023umassbionlpmediqachat2023llms}. 


Despite progress, datasets and methodologies often focus on dominant languages, lack multilingual support, and struggle with high-quality, clinically appropriate synthetic dialogues, as summarized in Table \ref{tab:dialogue_datasets}; this study aims to address these gaps by enhancing the availability and quality of Arabic-language medical dialogue data, generating contextually relevant dialogues for Arabic-speaking communities.
\FloatBarrier
\begin{table}[ht]
\centering
\caption{Summary of medical dialogue datasets from existing and synthetic sources.}
\label{tab:dialogue_datasets}
\small 
\begin{tabular}{|p{3cm}|p{2.5cm}|p{2.8cm}|p{3.2cm}|p{3.5cm}|}
\hline
\textbf{Dataset Name} & \textbf{Language} & \textbf{Medical Focus} & \textbf{Key Contribution} & \textbf{Limitations} \\ \hline
MeditOD \cite{saley-etal-2024-meditod} & English & Medical history-taking & High-quality annotation for dialogue modeling & Limited to English, small dataset size \\ \hline
MedDialog \cite{zeng-etal-2020-meddialog} & English, Chinese & General medical dialogue & Foundational resource for multilingual dialogues & Limited depth in specialized medical domains, potential annotation inconsistencies \\ \hline
MedDG \cite{liu2022meddgentitycentricmedicalconsultation} & Chinese & Entity-centric medical consultation & Dataset with annotations for diseases and symptoms & Restricted to Chinese, entity annotation may miss complex interactions \\ \hline
Synthetic Dialogues \cite{das2024syntheticpatientphysiciandialoguegeneration} & Multilingual & General medicine & Ensures privacy and linguistic diversity & Synthetic nature may reduce realism, limited validation against real data \\ \hline
Synthetic Arabic Medical Dialogues \cite{almutairi-etal-2024-synthetic} & Arabic (Najdi dialect) & General medicine & Addresses lack of Arabic medical datasets & Narrow dialect focus (Najdi), potential lack of scalability \\ \hline
Synthetic Clinical Documentation Dialogues \cite{wang2023umassbionlpmediqachat2023llms} & English & Clinical documentation & Improves data diversity and privacy compliance & Focused on documentation, less applicable to live dialogues \\ \hline
Arabic Healthcare Dataset (AHD) \cite{al2024ahd} & Arabic & General healthcare Q\&A & Supports NLP tasks like text classification and generation & General focus may lack depth in specific medical areas \\ \hline
MAQA \cite{Abdelhay2023Deep} & Arabic & Healthcare Q\&A in 20 specializations & Largest Arabic Medical Q\&A dataset & Size may include noise, limited to Q\&A format \\ \hline
\end{tabular}
\end{table}
\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EgyMed: Proposed Medical Dialogue Generation Pipeline}
\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{EgyMed.png} 
\caption{\centering EgyMed: Proposed Pipeline for generating medical dialogues.}
\Description{A diagram showing the proposed pipeline for generating medical dialogues.}
\label{fig:EgyMed}
\end{figure}

In this section, we illustrate our proposed approach, EgyMed, which is categorized into several phases. Figure \ref{fig:EgyMed} shows the general structure of EgyMed.
The method we employ starts with introducing user-specific metadata like gender, age group, and medical department. This metadata is then incorporated into prompt templates that simulate medical dialogues.
Subsequently, we employed two large language models (LLMs) - SILMA \cite{silma_01_2024} and GPT-4o \cite{gpt4o2024system} to create accurate and medically based Arabic dialogue. These dialogues represent real patient-doctor exchanges and cover various medical topics.
After the generation procedure, we extract essential data from the conversations to include in designated slots, which include patient history, symptoms, symptom level, lifestyle, and intent. This slot-filling stage converts the dialogues into structured representations appropriate for future Dialogue State Tracking (DST) tasks.

This pipeline yields the \textbf{\textit{EgyMed}} dataset, which is an Arabic medical dialogue dataset that covers a wide range of medical departments and contains extensive metadata that may be used for a variety of purposes.  Algorithm \ref{alg:egymedalgo} summarises the process of producing this dataset.

\begin{algorithm}
\caption{EgyMed Dataset Generation Pipeline}
\label{alg:egymedalgo}
\begin{algorithmic}[1]
\Require Set of departments $D$, age groups $A$, genders $G$
\Ensure a Structured dataset with dialogues and slots

\ForAll{combination $(d, a, g) \in D \times A \times G$}
    \State Construct metadata $M = \{d, a, g\}$
    \State Design prompt $P$ using $M$
    \ForAll{LLM $\in$ \{SILMA, GPT-4o\}}
        \State Generate dialogue $T$ using prompt $P$
        \State Extract slots $S = \{$History, Symptoms, Severity, Lifestyle, Intent$\}$
        \State Store $(M, T, S)$ in dataset
    \EndFor
\EndFor
\State \Return Final dataset $\mathcal{D}$
\end{algorithmic}
\end{algorithm}


\subsection{Dataset Description}
The dataset used in this study was synthetically generated using a medical chatbot framework that utilizes large language models (LLMs). This chatbot stimulates trustworthy medical dialogues between patients and a medical assistant covering various medical diseases, symptoms, and lifestyle factors.
A total of 500 medical dialogues in Egyptian Arabic and Modern Standard Arabic (MSA) were generated using two large language models: 250 dialogues were generated by the Silma LLM \cite{silma_01_2024}, and 250 dialogues were generated using the GPT-4o LLM API \cite{OpenAI_GPT4o_2024}.
Figure \ref{fig:dialogues_distribution} illustrates the distribution of medical dialogues across various departments in the generated dataset.

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=15cm, height=7cm]{dialogues_distribution.png} 
    \caption{Distribution of Medical Dialogues by Department}
    \Description{Distribution of Medical Dialogues by Department}
    \label{fig:dialogues_distribution}
\end{figure*}

\subsection{Metadata}
The generated medical dataset provides detailed metadata, which allows filtering, categorizing, and gaining access to dialogues designed for specific medical specialities and dialogue categories, increasing the dataset's usability.

The metadata can be categorized into two types:

\begin{itemize}
    \item \textbf{User Metadata:} Used to guide the prompt generation process. This includes:
    \begin{itemize}
        \item \textbf{Demographics \& Speaker Information:} The gender of the speaking person.
        \item \textbf{Age Group:} The age group of the patient.
        \item \textbf{Medical Departments:} The dataset includes various groups of 20 medical departments. Their distribution across the dialogues is illustrated in Figure \ref{fig:dialogues_distribution}.
    \end{itemize}

    \item \textbf{Extracted Slots:} Extracted information from the generated dialogues, defining dialogue state attributes:
    \begin{itemize}
        \item \textbf{Patient History:} Patient's medical history, including current medications or health conditions. 
        \item \textbf{Symptoms:} The reported symptoms by the patient.
        \item \textbf{Symptom Level:} This shows the severity level of the symptoms, categorized as high, moderate, or low.
        \item \textbf{Lifestyle:} Lifestyle factors affecting the patient's health.  
        \item \textbf{Intent:} The patient's intent in the conversation, such as requesting a diagnosis, asking for medication clarification, or confirming allergies.
    \end{itemize}
\end{itemize}

\subsection{Dialogue Generation}
The dataset was created using large language models (LLMs) combined with prompt engineering strategies.  Every conversation represents an interaction between a user and an assistant in a specific medical context. The user asks a question, and the LLM responds, ensuring that the dialogue matches the dataset's important features.

In the generated dialogues, user inputs are labelled as \textit{You}, while LLM-generated responses are labelled as \textit{Assistant}, as shown in Figure~\ref{fig:dialogue}. To generate these dialogues, two main LLMs were used. The generating method used a well-designed prompt that used Chain-of-Thought (CoT) reasoning to improve reply clarity and relevance to context.


 \FloatBarrier
\begin{figure}[htbp]
    \centering
    \includegraphics[width=14cm, height=6cm]{dialogue.png} 
    \caption{A Generated Sample Showcasing an Assistant-Patient Interaction}
    \Description{A Generated Sample Showcasing an Assistant-Patient Interaction}
    \label{fig:dialogue}
\end{figure}
\FloatBarrier

\subsubsection{\textbf{Prompt Engineering:}} is a tool that enhances the instructions and templates sent to the LLMs. Designing and optimizing prompts in the proper structure improves the accuracy, relevance, and quality of the output. The Prompt was designed as a one-shot Prompt with the CoT. 
CoT prompting allows the model to use reasoning in thinking, breaking the generation task into a sequence of steps to provide the most reliable and accurate output. The prompt used for dialogue generation is shown in Figure \ref{prompt:M_prompt}. This prompt ensures that the LLM generates a medical diagnosis only when sufficient patient information is available. It will request any missing details during the conversation and, once enough information is gathered, provide the diagnosis along with the reasons that led to it.

\begin{figure}[ht]
\centering
\begin{tcolorbox}[
  colback=black!5!white,
  colframe=black,
  fonttitle=\bfseries,
  title=Prompt,
  arc=5pt,
  boxrule=0.8pt,
  fontupper=\small, % or \footnotesize, \scriptsize
  width=\textwidth,
  % breakable
]
\begin{otherlanguage}{arabic}
أنت مساعد ذكي ومتخصص في المجالات الطبية. مهمتك هي تقديم تشخيص دقيق فقط عند توفر جميع المعلومات 
الضرورية عن حالة المريض. \\
إذا لم تكن المعلومات كافية، فاطلب من المستخدم التفاصيل المفقودة مثل مكان الألم، شدة الحالة، 
التاريخ الطبي، أو الأعراض المرافقة، وبدلاً من توجيهه للطبيب، حاول معرفة المزيد عن حالته بطرح أسئلة 
إضافية تتعلق بعمره و مصدر الأعراض أو الآلام. \\
عند توفر جميع المعلومات، قدم تشخيصاً يعتمد على الأعراض المقدمة، واذكر الأسباب التي دفعتك لهذا التشخيص 
مع اقتراح العلاجات الممكنة.
\end{otherlanguage}
\end{tcolorbox}
\caption{Designed prompt for dataset generation}
\Description{Designed prompt for dataset generation}
\label{prompt:M_prompt}
\end{figure}


\subsubsection{\textbf{SILMA:}}
The first model utilized in this study is SILMA AI \cite{silma_01_2024}. This large-scale language model has demonstrated superior performance in various Arabic language tasks, which makes it particularly suitable for many applications. For this research, we employed the quantized 4-bit version to generate 250 dialogues.
\subsubsection{\textbf{GPT-4o:}}
The Second model employed in this study is GPT-4o \cite{OpenAI_GPT4o_2024}, a state-of-the-art LLM known for its advanced capabilities across multiple languages, including Arabic. It surpasses previous iterations in efficiency, speed, and contextual understanding, making it highly suitable for business and research applications. The API of the LLM was used to generate the rest of the 250 dialogues.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results and Discussion}
This section will cover the details of the evaluation metric used to evaluate the generated dialogues and the model's performance on the LLMs used.

\subsection{Evaluation Metrics}
To assess the effectiveness of our proposed approach, we used five different evaluation metrics: BERTScore \cite{zhang2020bertscoreevaluatingtextgeneration}, RAGEval \cite{zhu2024ragevalscenariospecificrag}, LLM-to-LLM evaluation, Expert Evaluation, and Dataset Department Classification.

These metrics are widely employed to evaluate the generated dialogues by comparing them to a reference text, if applicable. Below, we briefly explain each metric.
\subsubsection{Standard Metrics:}


\paragraph{\textbf{BERTScore}:} An evaluation metric \cite{zhang2020bertscoreevaluatingtextgeneration} for text generation. BERTScore computes a similarity score for each token in the generated sentence ($X$) with each token in the ground truth sentence ($Y$) using contextual embeddings instead of exact matches. 

The BERTScore is defined as:
\begin{equation}
    \text{BERTScore} = \frac{1}{N} \sum_{i=1}^{N} \cos\left(\text{embedding}(X_i), \text{embedding}(Y_i)\right)
\end{equation}
where:
\begin{itemize}
    \item $N$: Number of tokens.
    \item $\text{embedding}(\cdot)$: Contextualized token embeddings from BERT.
    \item $\cos(\cdot)$: Cosine similarity.
\end{itemize}
 
 
\paragraph{\textbf{Completeness}:} An evaluation metric \cite{zhu2024ragevalscenariospecificrag} that measures how well the generated response captures the key information from the ground truth. It assesses whether the generated answer covers all important points from the ground truth. 

The Completeness score is defined as:
\begin{equation}
    \text{Comp}(A, K) = \frac{1}{|K|} \sum_{i=1}^{|K|} \mathbf{1}[A \, \text{covers} \, k_i]
\end{equation}
where:
\begin{itemize}
    \item $A$: The generated answer.
    \item $K = \{k_1, k_2, \ldots, k_n\}$: The set of key points from the ground truth.
    \item $\mathbf{1}[\cdot]$: An indicator function that evaluates whether $A$ covers $k_i$.
\end{itemize}


\paragraph{\textbf{Hallucination}:} A metric \cite{zhu2024ragevalscenariospecificrag} that measures the proportion of key points in the generated answer that contradict the ground truth.

The Hallucination score is defined as:
\begin{equation}
    \text{Hallu}(A, K) = \frac{1}{|K|} \sum_{i=1}^{|K|} \mathbf{1}[A \, \text{contradicts} \, k_i]
\end{equation}
where:
\begin{itemize}
    \item $A$: The generated response.
    \item $K = \{k_1, k_2, \ldots, k_n\}$: The set of key points from the ground truth.
    \item $\mathbf{1}[\cdot]$: An indicator function that evaluates whether $A$ contradicts $k_i$.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{LLM-to-LLM Evaluation}
To evaluate the generated medical dialogues, we employed the knowledge distillation concept, where we used a pre-trained Arabic medical LLM llama-2-7b-Arabic-medical \cite{engtig2025llama2arabicmedical} to automate assessment, ensuring efficient and scalable evaluation in healthcare applications. Given the computational demands of a 7-billion-parameter model, we applied the quantization to optimize resource usage while maintaining evaluation accuracy.

 The LLM was prompted to assess dialogue turns based on key criteria, including (1) Clarity and relevance, ensuring responses are clear, concise, and medically pertinent (Overall Average Clarity: 6.42/10); (2) \textit{Completeness of information}, evaluating whether the response provides sufficient medical context (Overall Average Completeness: 4.86/10); and (3) \textit{Appropriateness for a medical discussion}, checking alignment with professional healthcare standards (Overall Average Appropriateness: 6.89/10).  
The prompt that was used to guide the model's evaluation is shown in Figure \ref{fig:evaluationprompt}.
\begin{figure}[ht]
\centering
\begin{tcolorbox}[
  colback=black!5!white,
  colframe=black,
  fonttitle=\bfseries,
  title=Prompt,
  arc=5pt,
  boxrule=0.8pt,
  fontupper=\small, % or \footnotesize, \scriptsize
  width=\textwidth,
]
You are tasked with evaluating a response from a \{role\} in a medical conversation. The response provided is as follows:

Your evaluation should address the following key aspects:

\textbf{Clarity and Relevance:} Assess how clearly and effectively the information is communicated. Does the response directly address the question or issue raised, and is the language appropriate for the context of a medical discussion?

\textbf{Completeness of Information:} Determine whether the response includes all the necessary details to adequately address the medical topic. Are any crucial facts or steps omitted, and if so, should additional information have been provided?

\textbf{Appropriateness for Medical Discussion:} Evaluate if the response adheres to the expected level of professionalism, accuracy, and sensitivity required in a medical conversation. Is the tone suitable, and does the response demonstrate medical competence?

After considering these aspects, provide a succinct, constructive evaluation of the response that identifies strengths, weaknesses, and areas for improvement.
\end{tcolorbox}
\caption{Evaluation prompt used for response assessment}
\Description{Evaluation prompt used for response assessment}
\label{fig:evaluationprompt}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Expert Evaluation:}
To evaluate our generated dialogues thoroughly, we asked a medical expert—a junior medical doctor—to examine and score them on a scale 5, based on the correctness and clarity of the medical information. 
Figure \ref{fig:expert_domain} illustrates the average scores evaluated by the expert domain on a
scale of 1 to 5, where 5 is the highest score. 
According to the findings of the human expert, 409 of the 500 generated dialogues received a 5 out of 5, 88 received a 4 out of 5, and 3 received a 1 out of 5 score, resulting in an average score of 4.8 out of 5.

% \begin{figure*}[htbp]
%     \centering
%     \begin{minipage}[t]{0.48\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{expert_domain.png}
%         \caption{Distribution of Human-Evaluated Scores for Dialogues}
%         \label{fig:expert_domain}
%     \end{minipage}%
%     \hfill
%     \begin{minipage}[t]{0.48\textwidth}
%         \centering
%         \vspace{0.3cm} % Adjust as needed to match the figure caption alignment
%         \begin{tabular}{l c}
%         \toprule
%         \textbf{Evaluation Metric} & \textbf{Score} \\
%         \midrule
%         \textbf{Dialogue Classification} & \\
%         Average BERTScore F1 & 92.96\% \\
%         \midrule
%         \textbf{RAGEval} & \\
%         Completeness Score & 79.11\% \\
%         Hallucination Score & 20.89\% \\
%         \midrule
%         \textbf{LLM-to-LLM Evaluation} & \\
%         Overall Average Clarity & 6.42/10 \\
%         Overall Average Completeness & 4.86/10 \\
%         Overall Average Appropriateness & 6.89/10 \\
%         \midrule
%         \textbf{Expert Domain Score} & 4.8/5 \\
%         \bottomrule
%         \end{tabular}
%         \captionof{table}{Summary of experimental results}
%         \label{tab:results}
%     \end{minipage}
% \end{figure*}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\columnwidth]{expert_domain.png} 
    \caption{Distribution of Human-Evaluated Scores for Dialogues}
    \Description{Distribution of Human-Evaluated Scores for Dialogues}
    \label{fig:expert_domain}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Medical Department Prediction}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\paragraph{\textbf{Gemini 2.0 Flash}:}
We employed the Gemini 2.0 Flash \cite{Gemini2.0Flash} API to predict the department of each dialogue by the specific instructions provided in the prompt during the prediction model's implementation.
Gemini 2.0 Flash \cite{Gemini2.0Flash} was utilized in our implementation as a result of its improved performance in agentic experiences, sophisticated tasks, and reasoning.

\paragraph{ \textbf{Prompt Engineering}:}
We employed a sophisticated prompt engineering strategy to guide the Gemini API towards accurate medical department prediction. The core idea is to use "few-shot learning," where the model is provided with several examples of question-answer dialogues, their extracted key points, and the correct medical department prediction. These examples, which are shown in Figure~\ref{fig:random2}, serve as a template for the model, demonstrating the desired reasoning process and output format.

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=1\textwidth, height=1.5\textheight, keepaspectratio]{random2.png}
    \caption{A Randomly Selected Q\&A Example Utilized in the Medical Department Prediction Task Prompt}
    \Description{A Randomly Selected Q\&A Example Utilized in the Medical Department Prediction Task Prompt}
    \label{fig:random2}
\end{figure*}

The prompt explicitly instructs the model to act as a medical assistant, focusing on analyzing dialogues, extracting key information, and classifying the medical case accordingly. It also enforces a "Tree Chain of Thoughts" approach, breaking down the prediction process into sequential steps: dialogue analysis, symptom extraction, comparison with available
departments, and final prediction selection. The prompt carefully structures the input, presenting the dialogue, key points extracted from the patient’s question, the assistant’s answer, and a clear instruction to select one department from a predefined list of the dialogue dataset departments.



To achieve this, the model is prompted with the following structured instruction shown in Figure \ref{prompt:prompt32}. This structured approach ensures that the model follows a logical step-by-step process, leading to accurate and consistent medical department predictions.




\begin{figure}[ht]
\centering
\begin{tcolorbox}[
  colback=black!5!white,
  colframe=black,
  fonttitle=\bfseries,
  title=Prompt,
  arc=5pt,
  boxrule=0.8pt,
  fontupper=\small, % or \footnotesize, \scriptsize
  width=\textwidth,
  % breakable
]
\begin{otherlanguage}{arabic}
أنت طبيب مساعد متخصص في الطب العام، ومهمتك هي تحليل الحوارات بين المريض والطبيب، وتصنيف الحالة الطبية إلى القسم المناسب من القائمة التالية فقط

استخدم أسلوب شجرة الأفكار للتصنيف عبر الخطوات التالية:

تحديد الحوار: قم بتحديد المشكلة الأساسية التي يواجهها المريض من خلال تحليل السؤال والإجابة

استخراج الأعراض أو الشكوى الرئيسية: قم بتحديد الأعراض والعلامات السريرية البارزة المذكورة في الحوار

مقارنة مع الأقسام الطبية المتاحة: راجع جميع الأقسام المتاحة وحدد الأقرب بناءً على الأعراض والمعلومات المقدمة

اختبار التصنيف النهائي: اختر قسماً واحداً فقط من القائمة بناءً على الخطوات السابقة
\end{otherlanguage}
\end{tcolorbox}
\caption{Arabic classification prompt for medical assistant}
\Description{Arabic classification prompt for medical assistant}
\label{prompt:prompt32}
\end{figure}



The medical department's prediction process follows a structured and systematic workflow. First, a well-structured "Tree Chain of Thoughts" prompt is formulated, incorporating the dialogue, extracted key points, and a predefined instructional template enriched with few-shot examples. This prompt is then submitted to Gemini 2.0 Flash API for processing. Upon receiving the model’s response, we extract the predicted medical department along with its reasoning. To quantitatively assess performance, we compute the BERTScore-F1 between the predicted and ground truth medical departments for the dialogues in the dataset. This approach yielded an impressive Average BERTScore-F1 of 92.96\%, highlighting the effectiveness of our methodology in accurately predicting departments.


\subsection{Experimental Results}
This section summarizes the outcomes of our experiments. Table~\ref{tab:results} presents the results across various evaluation metrics.

\begin{table}[ht]
\centering
\caption{Summary of experimental results.}
\label{tab:results}
\begin{tabular}{l c}
\toprule
\textbf{Evaluation Metric} & \textbf{Score} \\
\midrule
\textbf{Dialogue Classification} & \\
Average BERTScore F1 & 92.96\% \\
\midrule
\textbf{RAGEval} & \\
Completeness Score & 79.11\% \\
Hallucination Score & 20.89\% \\
\midrule
\textbf{LLM-to-LLM Evaluation} & \\
Overall Average Clarity & 6.42/10 \\
Overall Average Completeness & 4.86/10 \\
Overall Average Appropriateness & 6.89/10 \\
\midrule
\textbf{Expert Domain Score} & 4.8/5 \\
\bottomrule
\end{tabular}
\end{table}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}



Our paper introduces a novel Arabic medical dialogue dataset comprising 500 dialogues in Egyptian Arabic and Modern Standard Arabic (MSA), generated through prompt engineering and leveraging SILMA \cite{silma_01_2024} and GPT-4o \cite{OpenAI_GPT4o_2024}. Addressing a resource gap for Arabic medical AI, the dataset underwent rigorous evaluation, including RAGEval \cite{zhu2024ragevalscenariospecificrag}, BERTScore \cite{zhang2020bertscoreevaluatingtextgeneration} (achieving 92.96\% for department prediction), LLM-to-LLM evaluation, and expert domain review (averaging 4.8/5).  The dataset's quality and potential in Arabic-language medical AI are evident. Future work will expand the dataset by increasing its size, balancing dialogue numbers across different departments, and incorporating more dialects. This valuable resource is essential for researchers and practitioners developing effective healthcare solutions for Arabic-speaking communities.

















%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Availability}
The dataset generated in this work will be made accessible upon request to the following repository: \url{https://github.com/EgyMed/EgyMed-Dataset}

\bibliographystyle{ACM-Reference-Format}
\bibliography{ref}


\end{document}
